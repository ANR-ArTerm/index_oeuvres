{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5bcfe57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_wikidata_id(url):\n",
    "    if not url:\n",
    "        return None\n",
    "    return url.rsplit(\"/\", 1)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0b7cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ann√©e inception (d√©but) : 1887\n",
      "Ann√©e inception (fin) : 1889\n",
      "Instance of : ['Q2319498', 'Q1440476', 'Q1440300', 'Q570116']\n",
      "Image : http://commons.wikimedia.org/wiki/Special:FilePath/Tour%20Eiffel%20Wikimedia%20Commons.jpg\n",
      "Latitude : 48.858296\n",
      "Longitude : 2.294479\n",
      "Countries : ['Q142']\n",
      "Cities : ['Q259463']\n",
      "Architects : ['Q778243']\n"
     ]
    }
   ],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "def parse_group_concat(value):\n",
    "    if value is None or value == \"\":\n",
    "        return []\n",
    "    return value.split(\"|\")\n",
    "\n",
    "def extract_year(date_string):\n",
    "    \"\"\"\n",
    "    Extrait l'ann√©e d'une date Wikidata du type '+1887-01-28T00:00:00Z'\n",
    "    et la retourne sous forme d'entier.\n",
    "    \"\"\"\n",
    "    if not date_string:\n",
    "        return None\n",
    "    \n",
    "    year_str = date_string.strip(\"+\").split(\"-\")[0]\n",
    "    \n",
    "    # Convertit en int pour permettre le tri\n",
    "    try:\n",
    "        return int(year_str)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_first_and_last_year(dates):\n",
    "    \"\"\"\n",
    "    Prend une liste de dates Wikidata et renvoie :\n",
    "    - premi√®re ann√©e (min)\n",
    "    - derni√®re ann√©e (max)\n",
    "    \"\"\"\n",
    "    if not dates:\n",
    "        return None, None\n",
    "\n",
    "    # Conversion des dates Wikidata en ann√©es enti√®res\n",
    "    years = [extract_year(d) for d in dates if d]\n",
    "\n",
    "    # Filtre les valeurs invalides\n",
    "    years = [y for y in years if y is not None]\n",
    "\n",
    "    if not years:\n",
    "        return None, None\n",
    "\n",
    "    # üî• TRI CHRONOLOGIQUE\n",
    "    years = sorted(years)\n",
    "\n",
    "    # Retourne la premi√®re et la derni√®re ann√©e\n",
    "    return years[0], years[-1]\n",
    "\n",
    "\n",
    "def get_first_or_none(values):\n",
    "    if not values:\n",
    "        return None\n",
    "    return values[0]\n",
    "\n",
    "def get_first_or_none_list(values):\n",
    "    \"\"\"\n",
    "    Renvoie une liste contenant uniquement la premi√®re valeur de la liste.\n",
    "    Si la liste est vide, renvoie [None].\n",
    "    \"\"\"\n",
    "    if not values:\n",
    "        return [None]\n",
    "    return [values[0]]\n",
    "\n",
    "def get_monument_data(qid):\n",
    "    sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\")\n",
    "\n",
    "    query = f\"\"\"\n",
    "    SELECT\n",
    "        (GROUP_CONCAT(DISTINCT STR(?inception); SEPARATOR=\"|\") AS ?inception)\n",
    "        (GROUP_CONCAT(DISTINCT STR(?instanceOf); SEPARATOR=\"|\") AS ?instanceOf)\n",
    "        (GROUP_CONCAT(DISTINCT STR(?image); SEPARATOR=\"|\") AS ?image)\n",
    "        (GROUP_CONCAT(DISTINCT STR(?country); SEPARATOR=\"|\") AS ?country)\n",
    "        (GROUP_CONCAT(DISTINCT STR(?city); SEPARATOR=\"|\") AS ?city)\n",
    "        (GROUP_CONCAT(DISTINCT STR(?lat); SEPARATOR=\"|\") AS ?lat)\n",
    "        (GROUP_CONCAT(DISTINCT STR(?lon); SEPARATOR=\"|\") AS ?lon)\n",
    "        (GROUP_CONCAT(DISTINCT STR(?architect); SEPARATOR=\"|\") AS ?architect)\n",
    "    WHERE {{\n",
    "      VALUES ?item {{ wd:{qid} }}\n",
    "\n",
    "      OPTIONAL {{ ?item wdt:P571 ?inception. }}\n",
    "      OPTIONAL {{ ?item wdt:P31 ?instanceOf. }}\n",
    "      OPTIONAL {{ ?item wdt:P18 ?image. }}\n",
    "      OPTIONAL {{ ?item wdt:P17 ?country. }}\n",
    "      OPTIONAL {{ ?item wdt:P131 ?city. }}\n",
    "\n",
    "      OPTIONAL {{\n",
    "        ?item wdt:P625 ?coords.\n",
    "        BIND(geof:latitude(?coords) AS ?lat)\n",
    "        BIND(geof:longitude(?coords) AS ?lon)\n",
    "      }}\n",
    "\n",
    "      OPTIONAL {{ ?item wdt:P84 ?architect. }}\n",
    "    }}\n",
    "    GROUP BY ?item\n",
    "    \"\"\"\n",
    "\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    results = sparql.query().convert()\n",
    "\n",
    "    row = results[\"results\"][\"bindings\"][0]\n",
    "\n",
    "    # Lecture des variables brutes\n",
    "    inception_list = [\n",
    "        extract_wikidata_id(a) for a in parse_group_concat(row.get(\"inception\", {}).get(\"value\")) if a\n",
    "    ]\n",
    "    instance_of_list = [\n",
    "        extract_wikidata_id(a) for a in parse_group_concat(row.get(\"instanceOf\", {}).get(\"value\")) if a\n",
    "    ]\n",
    "    image_list       = parse_group_concat(row.get(\"image\", {}).get(\"value\"))\n",
    "    country_list = [\n",
    "        extract_wikidata_id(a) for a in parse_group_concat(row.get(\"country\", {}).get(\"value\")) if a\n",
    "    ]\n",
    "    city_list = [\n",
    "        extract_wikidata_id(a) for a in parse_group_concat(row.get(\"city\", {}).get(\"value\")) if a\n",
    "    ]\n",
    "\n",
    "    lat_list         = parse_group_concat(row.get(\"lat\", {}).get(\"value\"))\n",
    "    lon_list         = parse_group_concat(row.get(\"lon\", {}).get(\"value\"))\n",
    "    architect_list = [\n",
    "        extract_wikidata_id(a) for a in parse_group_concat(row.get(\"architect\", {}).get(\"value\")) if a\n",
    "    ]\n",
    "\n",
    "\n",
    "    # üéØ Transformation :\n",
    "    first_image   = get_first_or_none(image_list)\n",
    "    first_lat     = float(get_first_or_none(lat_list)) if lat_list else None\n",
    "    first_lon     = float(get_first_or_none(lon_list)) if lon_list else None\n",
    "    first_city    = get_first_or_none_list(city_list)\n",
    "    first_country = get_first_or_none_list(country_list)\n",
    "    first_year, last_year = get_first_and_last_year(inception_list)\n",
    "\n",
    "\n",
    "    # Variables finales\n",
    "    return (\n",
    "        first_year,       # ‚úî ann√©e de d√©but\n",
    "        last_year,        # ‚úî ann√©e de fin\n",
    "        instance_of_list,\n",
    "        first_image,      \n",
    "        first_country,\n",
    "        first_city,\n",
    "        first_lat,        # ‚úîÔ∏è float\n",
    "        first_lon,        # ‚úîÔ∏è float\n",
    "        architect_list\n",
    "    )\n",
    "\n",
    "\n",
    "# Exemple : Tour Eiffel\n",
    "(\n",
    "    first_year,\n",
    "    last_year,\n",
    "    instance_of,\n",
    "    image,\n",
    "    countries,\n",
    "    cities,\n",
    "    lat,\n",
    "    lon,\n",
    "    architects\n",
    ") = get_monument_data(\"Q243\")\n",
    "\n",
    "print(\"Ann√©e inception (d√©but) :\", first_year)\n",
    "print(\"Ann√©e inception (fin) :\", last_year)\n",
    "print(\"Instance of :\", instance_of)\n",
    "print(\"Image :\", image)\n",
    "print(\"Latitude :\", lat)\n",
    "print(\"Longitude :\", lon)\n",
    "print(\"Countries :\", countries)\n",
    "print(\"Cities :\", cities)\n",
    "print(\"Architects :\", architects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954a3009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ann√©e inception (d√©but) : 1887\n",
      "Ann√©e inception (fin) : 1889\n",
      "Instance of : ['Q2319498', 'Q1440476', 'Q1440300', 'Q570116']\n",
      "Image : http://commons.wikimedia.org/wiki/Special:FilePath/Tour%20Eiffel%20Wikimedia%20Commons.jpg\n",
      "Latitude : 48.858296\n",
      "Longitude : 2.294479\n",
      "Countries : ['Q142']\n",
      "Cities : ['Q259463']\n",
      "Architects : ['Q778243']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def wikidata_to_xml_ids_or_qid(qid_list, csv_path):\n",
    "    # si pas trouv√© ‚Üí on garde le QID\n",
    "    # mapping wikidata_qid -> xml_id\n",
    "    # √† utiliser pour les personnes et les lieux\n",
    "    mapping = {}\n",
    "\n",
    "    with open(csv_path, newline=\"\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            mapping[row[\"wikidata_qid\"]] = row[\"xml_id\"]\n",
    "\n",
    "    # si pas trouv√© ‚Üí on garde le QID\n",
    "    return [mapping.get(qid, qid) for qid in qid_list]\n",
    "\n",
    "import csv\n",
    "\n",
    "def wikidata_to_xml_ids_or_none(qid_list, csv_path):\n",
    "    \"\"\"\n",
    "    √Ä utiliser pour les typologies / techniques.\n",
    "    - √©vite les doublons\n",
    "    - ignore les labels vides\n",
    "    - retourne un seul label ou None\n",
    "    \"\"\"\n",
    "    if isinstance(qid_list, str):\n",
    "        qid_list = [qid_list]\n",
    "\n",
    "    labels_set = set()\n",
    "\n",
    "    with open(csv_path, newline=\"\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.DictReader(f, delimiter=\";\")\n",
    "        for row in reader:\n",
    "            qid = row.get(\"wikidata_qid\")\n",
    "            label = row.get(\"label_fr\")\n",
    "\n",
    "            if qid in qid_list and label:\n",
    "                labels_set.add(label.strip())\n",
    "\n",
    "    if not labels_set:\n",
    "        return None\n",
    "\n",
    "    # retourne UN seul label (stable)\n",
    "    return sorted(labels_set)[0]\n",
    "\n",
    "\n",
    "print(\"Ann√©e inception (d√©but) :\", first_year)\n",
    "print(\"Ann√©e inception (fin) :\", last_year)\n",
    "print(\"Instance of :\", instance_of)\n",
    "print(\"Image :\", image)\n",
    "print(\"Latitude :\", lat)\n",
    "print(\"Longitude :\", lon)\n",
    "print(\"Countries :\", countries)\n",
    "print(\"Cities :\", cities)\n",
    "print(\"Architects :\", architects)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c25d7ae",
   "metadata": {},
   "source": [
    "# Partie 2 constitution du CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c549acec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "input_csv=\"\"\n",
    "\n",
    "def monuments_wikidata_to_csv(input_csv, output_csv):\n",
    "    with open(input_csv, newline=\"\", encoding=\"utf-8\") as infile, \\\n",
    "         open(output_csv, \"w\", newline=\"\", encoding=\"utf-8\") as outfile:\n",
    "\n",
    "        reader = csv.DictReader(infile)\n",
    "        writer = csv.writer(outfile, delimiter=\";\")\n",
    "\n",
    "        # En-t√™te du CSV de sortie\n",
    "        writer.writerow([\n",
    "            \"qid\",\n",
    "            \"first_year\",\n",
    "            \"last_year\",\n",
    "            \"instance_of\",\n",
    "            \"image\",\n",
    "            \"country\",\n",
    "            \"city\",\n",
    "            \"latitude\",\n",
    "            \"longitude\",\n",
    "            \"architects\"\n",
    "        ])\n",
    "\n",
    "        for row in reader:\n",
    "            qid = extract_wikidata_id(row.get(\"url_wikidata\"))\n",
    "            if not qid:\n",
    "                continue\n",
    "\n",
    "            (\n",
    "                first_year,\n",
    "                last_year,\n",
    "                instance_of,\n",
    "                image,\n",
    "                country,\n",
    "                city,\n",
    "                lat,\n",
    "                lon,\n",
    "                architects\n",
    "            ) = get_monument_data(qid)\n",
    "\n",
    "            writer.writerow([\n",
    "                qid,\n",
    "                first_year,\n",
    "                last_year,\n",
    "                instance_of,\n",
    "                image,\n",
    "                country,\n",
    "                city,\n",
    "                lat,\n",
    "                lon,\n",
    "                architects\n",
    "            ])\n",
    "\n",
    "monuments_wikidata_to_csv(\"ex_wikidata.csv\", \"ex_wikidata2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8fb23a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import ast\n",
    "from collections import Counter\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "def compter_instance_of(csv_path, colonne=\"instance_of\"):\n",
    "    counter = Counter()\n",
    "\n",
    "    with open(csv_path, newline=\"\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.DictReader(f, delimiter=\";\")\n",
    "        for row in reader:\n",
    "            value = row.get(colonne)\n",
    "            if not value:\n",
    "                continue\n",
    "\n",
    "            # Convertit la string \"['Q1', 'Q2']\" en vraie liste\n",
    "            try:\n",
    "                qids = ast.literal_eval(value)\n",
    "            except (ValueError, SyntaxError):\n",
    "                continue\n",
    "\n",
    "            for qid in qids:\n",
    "                counter[qid] += 1\n",
    "\n",
    "    return counter\n",
    "\n",
    "counts = compter_instance_of(\"ex_wikidata2.csv\")\n",
    "\n",
    "# Top 10 des instance_of les plus fr√©quents\n",
    "\n",
    "sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\")\n",
    "\n",
    "with open(\"instance_of_counts.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f, delimiter=\";\")\n",
    "    writer.writerow([\"wikidata_qid\", \"label_fr\", \"count\"])\n",
    "\n",
    "    for qid, nb in counts.most_common():  # TOUS les QID\n",
    "        query = f\"\"\"\n",
    "        SELECT ?label WHERE {{\n",
    "          wd:{qid} rdfs:label ?label .\n",
    "          FILTER (lang(?label) = \"fr\")\n",
    "        }}\n",
    "        LIMIT 1\n",
    "        \"\"\"\n",
    "\n",
    "        sparql.setQuery(query)\n",
    "        sparql.setReturnFormat(JSON)\n",
    "\n",
    "        try:\n",
    "            results = sparql.query().convert()\n",
    "            label = results[\"results\"][\"bindings\"][0][\"label\"][\"value\"]\n",
    "        except Exception:\n",
    "            label = \"\"\n",
    "\n",
    "        writer.writerow([qid, label, nb])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c0f9dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"instance_of_counts.csv\", newline=\"\", encoding=\"utf-8\") as f, \\\n",
    "     open(\"labels_typology.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as o:\n",
    "\n",
    "    reader = csv.reader(f, delimiter=\";\")\n",
    "    writer = csv.writer(o, delimiter=\";\")\n",
    "\n",
    "    for row in reader:\n",
    "        del row[2]  # supprime la 4·µâ colonne\n",
    "        writer.writerow(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
